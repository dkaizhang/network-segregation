{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook calculates various statistics for networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-070aa520a41e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mticker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFormatStrFormatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate testing\n",
    "TEST = False\n",
    "PLOTS = True\n",
    "PATH = \"./saved-48\"\n",
    "NAME = \"base\"\n",
    "\n",
    "SEGPLOTS = False\n",
    "# SEGPATH = [\"./saved-b13\", \"./saved-b15\", \"./saved-48\", \"./saved-b19\"]\n",
    "# SEGPATH = [\"./saved-4grp\", \"./saved-mm\", \"./saved-48\"]\n",
    "SEGPATH = [\"./saved-4type\", \"./saved-cross\", \"./saved-seg\", \"./saved-48\"]\n",
    "SEGNAME = \"type\"\n",
    "\n",
    "GET_SEEDS = False\n",
    "SEEDPATH = \"./saved-4type\"\n",
    "\n",
    "\n",
    "# Global constants\n",
    "# COLOURS = ['firebrick', 'tomato', 'peru','darkgreen', 'mediumseagreen', 'teal']\n",
    "# standard\n",
    "COLOURS = ['firebrick', 'tomato','darkgreen', 'mediumseagreen']\n",
    "# 4 type\n",
    "# COLOURS = ['firebrick','darkgreen','navy','purple','tomato','mediumseagreen','cornflowerblue','violet']\n",
    "# 4 grp\n",
    "# COLOURS = ['firebrick','tomato','darkgreen','mediumseagreen','navy','cornflowerblue','purple','violet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_colour_map(G, colours):\n",
    "\n",
    "    if (len(colours) < len(G.graph['population_breakdown'] * G.graph['population_breakdown'][0])):\n",
    "        raise ValueError(\"Missing colours\")\n",
    "    \n",
    "    colour_map = []\n",
    "\n",
    "    for node in G.nodes:\n",
    "        grp = G.nodes[node]['group']\n",
    "        tp = G.nodes[node]['type']\n",
    "        colour_map.append(colours[grp * len(G.graph['population_breakdown'][0]) + tp])\n",
    "    \n",
    "    return colour_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a matrix of size n x n showing inter- and intra group connections\n",
    "def stratify_connections(G):\n",
    "    \n",
    "    groups = len(G.graph['population_breakdown']) # number of social groups\n",
    "    \n",
    "    group_connections = np.zeros((groups, groups), dtype=int)\n",
    "                                  \n",
    "    for edge in G.edges:\n",
    "        node1 = G.nodes[edge[0]]\n",
    "        node2 = G.nodes[edge[1]]\n",
    "        \n",
    "        # populate upper triangle first\n",
    "        lower_edge = min(node1['group'], node2['group'])\n",
    "        upper_edge = max(node1['group'], node2['group'])\n",
    "        group_connections[lower_edge, upper_edge] += 1\n",
    "    \n",
    "    # copy upper triangle into lower triangle\n",
    "    group_connections = group_connections + np.transpose(group_connections) - np.diag(np.diag(group_connections))\n",
    "    \n",
    "    return group_connections\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connectivity(G):\n",
    "    connection_matrix = stratify_connections(G)\n",
    "    \n",
    "    intra_connections = np.trace(connection_matrix)\n",
    "    inter_connections = np.sum(np.triu(connection_matrix,1))\n",
    "    all_connections = intra_connections + inter_connections\n",
    "    \n",
    "    all_possible_connections = 0.5 * len(G) * (len(G) - 1)\n",
    "    \n",
    "    return all_connections / all_possible_connections\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interconnect_ratio(connection_matrix):\n",
    "    # get number of connections by typology\n",
    "    intra_connections = np.trace(connection_matrix)\n",
    "    inter_connections = np.sum(np.triu(connection_matrix,1))\n",
    "    all_connections = intra_connections + inter_connections\n",
    "    \n",
    "    if (all_connections == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return inter_connections / all_connections\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_freeman_segregation(G):\n",
    "    \n",
    "    # get matrix of all connections\n",
    "    connection_matrix = stratify_connections(G)\n",
    "    \n",
    "    proportion_inter = get_interconnect_ratio(connection_matrix)\n",
    "    \n",
    "    sum_of_squared_n = 0\n",
    "    sum_of_n = 0\n",
    "    for group in G.graph['population_breakdown']:\n",
    "        sum_of_squared_n += sum(group) ** 2\n",
    "        sum_of_n += sum(group) \n",
    "    \n",
    "    freeman = 1 - (proportion_inter * sum_of_n * (sum_of_n - 1)) / (sum_of_n ** 2 - sum_of_squared_n)\n",
    "    \n",
    "    return freeman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_incremental_segregation(G_IC, G_C):\n",
    "    # get matrix of all connections\n",
    "    connection_matrix_IC = stratify_connections(G_IC)\n",
    "    connection_matrix_C = stratify_connections(G_C)\n",
    "    \n",
    "    proportion_inter_IC = get_interconnect_ratio(connection_matrix_IC)\n",
    "    proportion_inter_C = get_interconnect_ratio(connection_matrix_C)\n",
    "    \n",
    "    # not defined if complete information case is empty\n",
    "    if (proportion_inter_C == 0):\n",
    "        return np.nan\n",
    "    return (proportion_inter_C - proportion_inter_IC) / proportion_inter_C\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_shortest_path(G):\n",
    "    avg_shortest_path = []\n",
    "    for C in (G.subgraph(c).copy() for c in nx.connected_components(G)):\n",
    "        avg_shortest_path.append(nx.average_shortest_path_length(C))\n",
    "        \n",
    "    return avg_shortest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information(G):\n",
    "    return np.sum(G.graph['information']) / (len(G) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_var(metric):\n",
    "    average = []\n",
    "    variance = []\n",
    "    for m in metric:\n",
    "        avg = sum(m) / len(m)\n",
    "        var = sum((x-avg)**2 for x in m) / len(m)\n",
    "        average.append(avg)\n",
    "        variance.append(var)\n",
    "    return average, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(G):\n",
    "    \n",
    "    freeman = calculate_freeman_segregation(G)\n",
    "    \n",
    "    cliques = nx.graph_number_of_cliques(G)\n",
    "\n",
    "    if (len(calculate_avg_shortest_path(G)) > 0):\n",
    "        avg_shortest_path = sum(calculate_avg_shortest_path(G)) / len(calculate_avg_shortest_path(G))\n",
    "    \n",
    "    if (len(nx.degree_centrality(G)) > 0):\n",
    "        dc = nx.degree_centrality(G).values()\n",
    "        avg_degree_centrality = sum(dc) / len(dc)\n",
    "        var_degree_centrality = sum((x-avg_degree_centrality)**2 for x in dc) / len(dc)\n",
    "    \n",
    "    information = calculate_information(G)\n",
    "        \n",
    "    return freeman, cliques, avg_shortest_path, avg_degree_centrality, var_degree_centrality, information\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_metrics(G):\n",
    "    freeman, cliques, avg_shortest_path, avg_degree_centrality, var_degree_centrality, information = get_metrics(G)\n",
    "    \n",
    "    print(\"========================================================================\")\n",
    "    print(\"This graph has %s nodes with population: %s\" %(len(G), G.graph['population_breakdown']))\n",
    "    print(\"The parameters are, delta=%s, c_l=%s, c_h=%s\" %(G.graph['delta'], G.graph['cost_low'], G.graph['cost_high']))\n",
    "    print(\"Convergence: %s after %s periods\" %(G.graph['converged'], G.graph['epochs']))\n",
    "    print(\"Freeman's SI: %s\" %round(freeman,4))\n",
    "    print(\"Cliques: %s\" %cliques)\n",
    "    print(\"Avg shortest path: %s\" %round(avg_shortest_path,4))\n",
    "    print(\"Avg degree centrality: %s\" %round(avg_degree_centrality,4))\n",
    "    print(\"Var degree centrality: %s\" %round(var_degree_centrality,4))\n",
    "    print(\"Information: %s\" %round(information,4))\n",
    " \n",
    "    print(\"Adjacency matrix:\")\n",
    "    print(nx.adjacency_matrix(G).todense())\n",
    "    print(\"========================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to demonstrate how pickles are read and metrics are displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and display a pickled graph\n",
    "read = False\n",
    "pickle_path = f\"{PATH}/IC-0-ch1.0-belief6.gpickle\"\n",
    "if (read):\n",
    "    G = nx.read_gpickle(pickle_path)\n",
    "    colour_map = create_colour_map(G, COLOURS)\n",
    "    nx.draw(G, node_color=colour_map, with_labels=True)\n",
    "    plt.show()\n",
    "    display_metrics(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and display a pickled graph\n",
    "read = False\n",
    "pickle_path = f\"{PATH}/C-0-ch1.25-belief6.gpickle\"\n",
    "if (read):\n",
    "    G = nx.read_gpickle(pickle_path)\n",
    "    colour_map = create_colour_map(G, COLOURS)\n",
    "    nx.draw(G, node_color=colour_map, with_labels=True)\n",
    "    plt.show()\n",
    "    display_metrics(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are used to read batches of graphs and compute various statistics using the above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_convergence(root, belief, case, files, increments):\n",
    "    convergence_IC = []\n",
    "    convergence_C = []\n",
    "    convergence_R = []\n",
    "    \n",
    "    for cost in increments:\n",
    "        # temporary arrays for each increment\n",
    "\n",
    "        conv_IC = []\n",
    "        conv_C = []\n",
    "        conv_R = []\n",
    "\n",
    "        for iteration in range(0,files):\n",
    "            path_IC = root + \"/IC-%s-%s%s-belief%s.gpickle\" %(iteration, case, cost, belief)\n",
    "            path_C = root + \"/C-%s-%s%s-belief%s.gpickle\" %(iteration, case, cost, belief)\n",
    "            path_R = root + \"/IC-%s-%s%s-belief%s.gpickle\" %(iteration, case, cost, 0)\n",
    "            G_IC = nx.read_gpickle(path_IC)\n",
    "            G_C = nx.read_gpickle(path_C)\n",
    "            G_R = nx.read_gpickle(path_R)\n",
    "\n",
    "            if (G_IC.graph['converged'] and G_C.graph['converged'] and G_R.graph['converged']):  \n",
    "                \n",
    "                # epochs to convergence as tuples (IC, C)\n",
    "                c_IC = G_IC.graph['epochs']\n",
    "                c_C = G_C.graph['epochs']\n",
    "                c_R = G_R.graph['epochs']\n",
    "                conv_IC.append(c_IC)\n",
    "                conv_C.append(c_C)\n",
    "                conv_R.append(c_R)\n",
    "                \n",
    "        convergence_IC.append(conv_IC)\n",
    "        convergence_C.append(conv_C)\n",
    "        convergence_R.append(conv_R)\n",
    "\n",
    "    return convergence_IC, convergence_C, convergence_R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_attribute(option, root, belief, case, files, increments):\n",
    "    \n",
    "    IC = np.zeros((len(increments), files), dtype=int)\n",
    "    C = np.zeros((len(increments), files), dtype=int)\n",
    "    R = np.zeros((len(increments), files), dtype=int)\n",
    "    \n",
    "    for index, cost in enumerate(increments):\n",
    "        for iteration in range(0,files):\n",
    "            path_IC = root + \"/IC-%s-%s%s-belief%s.gpickle\" %(iteration, case, cost, belief)\n",
    "            path_C = root + \"/C-%s-%s%s-belief%s.gpickle\" %(iteration, case, cost, belief)\n",
    "            path_R = root + \"/IC-%s-%s%s-belief%s.gpickle\" %(iteration, case, cost, 0)\n",
    "            G_IC = nx.read_gpickle(path_IC)\n",
    "            G_C = nx.read_gpickle(path_C)\n",
    "            G_R = nx.read_gpickle(path_R)\n",
    "            \n",
    "            if option == 0:\n",
    "                IC[index, iteration] = int(G_IC.graph['converged'])\n",
    "                C[index, iteration] = int(G_C.graph['converged'])\n",
    "                R[index, iteration] = int(G_R.graph['converged'])\n",
    "\n",
    "            if option == 1:\n",
    "                IC[index, iteration] = int(G_IC.graph['epochs'])\n",
    "                C[index, iteration] = int(G_C.graph['epochs'])\n",
    "                R[index, iteration] = int(G_R.graph['epochs'])\n",
    "    \n",
    "    return IC, C, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opens up all files specified in the directory passed in as root and first calculates statistics for each run before averaging across all runs\n",
    "def calculate_stats(root, belief, case, files, increments, base=True):\n",
    "\n",
    "    # arrays to be returned\n",
    "    freeman = []\n",
    "    incr_segregation_C = []\n",
    "    incr_segregation_R = []\n",
    "#     cliques_IC = []\n",
    "#     cliques_C = []\n",
    "#     avg_shortest_path_IC = []\n",
    "#     avg_shortest_path_C = []\n",
    "    avg_degree_centrality_IC = []\n",
    "    avg_degree_centrality_C = []\n",
    "    avg_degree_centrality_R = []\n",
    "#     var_degree_centrality_IC = []\n",
    "#     var_degree_centrality_C = []\n",
    "    information_IC = []\n",
    "    information_R = []\n",
    "    \n",
    "    for cost in increments:\n",
    "        # temporary arrays for each increment\n",
    "        free = []\n",
    "        incr_seg_C = []\n",
    "        incr_seg_R = []\n",
    "#         cliq_IC = []\n",
    "#         cliq_C = []\n",
    "#         asp_IC = []\n",
    "#         asp_C = []\n",
    "        adc_IC = []\n",
    "        adc_C = []\n",
    "        adc_R = []\n",
    "#         vdc_IC = []\n",
    "#         vdc_C = []        \n",
    "        info_IC = []\n",
    "        info_R = []\n",
    "        \n",
    "        for iteration in range(0,files):\n",
    "            path_IC = root + \"/IC-%s-%s%s-belief%s.gpickle\" %(iteration, case, cost, belief)\n",
    "            G_IC = nx.read_gpickle(path_IC)\n",
    "            \n",
    "            if base:\n",
    "                path_C = root + \"/C-%s-%s%s-belief%s.gpickle\" %(iteration, case, cost, belief)\n",
    "                path_R = root + \"/IC-%s-%s%s-belief%s.gpickle\" %(iteration, case, cost, 0)\n",
    "                G_C = nx.read_gpickle(path_C)\n",
    "                G_R = nx.read_gpickle(path_R)\n",
    "\n",
    "            # freeman and incremental segregation\n",
    "            f = calculate_freeman_segregation(G_IC)\n",
    "            free.append(f)\n",
    "            \n",
    "            if base:\n",
    "                i_s_C = calculate_incremental_segregation(G_IC, G_C)\n",
    "                i_s_R = calculate_incremental_segregation(G_IC, G_R)                \n",
    "                incr_seg_C.append(i_s_C)\n",
    "                incr_seg_R.append(i_s_R)\n",
    "\n",
    "            # cliques\n",
    "#                 cq_IC = nx.graph_number_of_cliques(G_IC)\n",
    "#                 cq_C = nx.graph_number_of_cliques(G_C)\n",
    "\n",
    "#                 cliq_IC.append(cq_IC)   \n",
    "#                 cliq_C.append(cq_C)   \n",
    "\n",
    "            # avg shortest path\n",
    "#                 asp_components_IC = calculate_avg_shortest_path(G_IC)\n",
    "#                 asp_components_C = calculate_avg_shortest_path(G_C)\n",
    "\n",
    "#                 if (len(asp_components_IC) > 0 and len(asp_components_C) > 0):\n",
    "#                     a_IC = sum(asp_components_IC) / len(asp_components_IC)\n",
    "#                     a_C = sum(asp_components_C) / len(asp_components_C)\n",
    "#                     asp_IC.append(a_IC)\n",
    "#                     asp_C.append(a_C)\n",
    "\n",
    "            # degree centrality\n",
    "            dc_IC = nx.degree_centrality(G_IC)\n",
    "            avg_dc_IC = sum(dc_IC.values())/len(dc_IC.values())\n",
    "\n",
    "            if base:\n",
    "                dc_C = nx.degree_centrality(G_C)\n",
    "                dc_R = nx.degree_centrality(G_R)\n",
    "                avg_dc_C = sum(dc_C.values())/len(dc_C.values())\n",
    "                avg_dc_R = sum(dc_R.values())/len(dc_R.values())\n",
    "\n",
    "#                 var_dc_IC = sum((x-avg_dc_IC)**2 for x in dc_IC.values()) / len(dc_IC.values())\n",
    "#                 var_dc_C = sum((x-avg_dc_C)**2 for x in dc_C.values()) / len(dc_C.values())\n",
    "\n",
    "            adc_IC.append(avg_dc_IC)\n",
    "            if base:\n",
    "                adc_C.append(avg_dc_C)\n",
    "                adc_R.append(avg_dc_R)\n",
    "#                 vdc_IC.append(var_dc_IC)\n",
    "#                 vdc_C.append(var_dc_C)\n",
    "\n",
    "            # information\n",
    "            inf_IC = calculate_information(G_IC)\n",
    "            info_IC.append(inf_IC)\n",
    "            if base:\n",
    "                inf_R = calculate_information(G_R)\n",
    "                info_R.append(inf_R)\n",
    "                \n",
    "        freeman.append(free)\n",
    "        if base:\n",
    "            incr_segregation_C.append(incr_seg_C)\n",
    "            incr_segregation_R.append(incr_seg_R)\n",
    "#         cliques_IC.append(cliq_IC)\n",
    "#         cliques_C.append(cliq_C)\n",
    "#         avg_shortest_path_IC.append(asp_IC)\n",
    "#         avg_shortest_path_C.append(asp_C)\n",
    "        avg_degree_centrality_IC.append(adc_IC)\n",
    "        if base:\n",
    "            avg_degree_centrality_C.append(adc_C)\n",
    "            avg_degree_centrality_R.append(adc_R)\n",
    "#         var_degree_centrality_IC.append(vdc_IC)\n",
    "#         var_degree_centrality_C.append(vdc_C)\n",
    "        information_IC.append(info_IC)\n",
    "        if base:\n",
    "            information_R.append(info_R)\n",
    "    \n",
    "    return freeman, incr_segregation_C, incr_segregation_R, \\\n",
    "            avg_degree_centrality_IC, avg_degree_centrality_C, avg_degree_centrality_R, \\\n",
    "            information_IC, information_R "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(i, axs, label, increments, \\\n",
    "            freeman, incr_segregation_C, incr_segregation_R, \\\n",
    "            avg_degree_centrality_IC, avg_degree_centrality_C, avg_degree_centrality_R, \\\n",
    "            information_IC, information_R):\n",
    "    \n",
    "    freeman_avg, freeman_var = calculate_avg_var(freeman)\n",
    "    incr_segregation_C_avg, incr_segregation_C_var = calculate_avg_var(incr_segregation_C)\n",
    "    incr_segregation_R_avg, incr_segregation_R_var = calculate_avg_var(incr_segregation_R)\n",
    "    \n",
    "    smallfont = 14\n",
    "    largefont = 18\n",
    "    lw = 4\n",
    "    ms = 8\n",
    "    labelpad_y = -5\n",
    "    labelpad_x = 5\n",
    "    \n",
    "    main_line = 'dashed'\n",
    "    sub_line = 'solid'\n",
    "    \n",
    "    ###\n",
    "    ax1 = axs[0, i]\n",
    "    line1, = ax1.plot(increments, freeman_avg, color='crimson', marker='o', linestyle=main_line, linewidth=lw, markersize=ms)\n",
    "    line2, = ax1.plot(increments, incr_segregation_C_avg, color='mediumseagreen', linestyle=sub_line, linewidth=lw, markersize=ms)\n",
    "    line3, = ax1.plot(increments, incr_segregation_R_avg, color='royalblue', linestyle=sub_line, linewidth=lw, markersize=ms)\n",
    "\n",
    "    ax1.tick_params(labelsize = smallfont)\n",
    "#     ax1.set_xlabel(label, fontsize=largefont)\n",
    "    if i == 0:\n",
    "        ax1.set_ylabel('Segregation \\n Index', fontsize=largefont,labelpad=labelpad_y)\n",
    "    if i == 1:\n",
    "        ax1.legend((line1, line2, line3), ('Freeman\\'s SI', 'ISI complete', 'ISI rational'), fontsize=smallfont, loc='upper left')\n",
    "    ax1.set_xlim(increments[0] - 0.01, increments[-1] + 0.01)\n",
    "    ax1.set_xticks(np.arange(increments[0], increments[-1] + 0.2, 0.2))\n",
    "    ax1.set_ylim(-0.2, 1.1)\n",
    "    ax1.set_yticks(np.arange(-0.2, 1.2, 0.2))\n",
    "    \n",
    "    ###\n",
    "    info_IC, info_IC_var = calculate_avg_var(information_IC)\n",
    "    info_R, info_R_var = calculate_avg_var(information_R)\n",
    "\n",
    "    ax2 = axs[1, i]\n",
    "    line1, = ax2.plot(increments, info_IC, color='crimson', marker='o', linestyle=main_line, linewidth=lw, markersize=ms)\n",
    "    line2, = ax2.plot(increments, info_R, color='royalblue', linestyle=sub_line, linewidth=lw, markersize=ms)\n",
    "\n",
    "    ax2.tick_params(labelsize = smallfont)\n",
    "#     ax2.set_xlabel(label, fontsize=largefont)\n",
    "    if i == 0:\n",
    "        ax2.set_ylabel('Proportion of \\n Discovery', fontsize=largefont, labelpad=labelpad_y)\n",
    "    if i == 1:\n",
    "        ax2.legend((line1, line2), ('Biased', 'Rational'), fontsize=smallfont, loc='lower left')\n",
    "    ax2.set_xlim(increments[0] - 0.01, increments[-1] + 0.01)\n",
    "    ax2.set_xticks(np.arange(increments[0], increments[-1] + 0.2, 0.2))\n",
    "    ax2.set_ylim(-0.01,0.71)\n",
    "\n",
    "    ###\n",
    "#     cliq_IC, cliq_IC_var = calculate_avg_var(cliques_IC)\n",
    "#     cliq_C, cliq_C_var = calculate_avg_var(cliques_C)\n",
    "    \n",
    "#     ax3 = axs[1,1]\n",
    "#     line1, = ax3.plot(increments, cliq_IC, color='royalblue', marker='o', linestyle='dashed', linewidth=lw, markersize=ms)\n",
    "#     line2, = ax3.plot(increments, cliq_C, color='royalblue', linestyle='solid', linewidth=lw, markersize=ms)\n",
    "#     ax3.tick_params(labelsize = smallfont)\n",
    "#     ax3.set_xlabel(label, fontsize=largefont)\n",
    "#     ax3.set_ylabel('Number of Cliques', fontsize=largefont)\n",
    "#     ax3.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "#     ax3.legend((line1, line2), ('Incomplete Info', 'Complete Info'), fontsize=smallfont)\n",
    "\n",
    "#     asp_IC, asp_IC_var = calculate_avg_var(avg_shortest_path_IC)\n",
    "#     asp_C, asp_C_var = calculate_avg_var(avg_shortest_path_C)\n",
    "    \n",
    "#     ax4 = axs[1,2]\n",
    "#     line1, = ax4.plot(increments, asp_IC, color='peru', marker='o', linestyle='dashed', linewidth=lw, markersize=ms)\n",
    "#     line2, = ax4.plot(increments, asp_C, color='peru', linestyle='solid', linewidth=lw, markersize=ms)\n",
    "#     ax4.tick_params(labelsize = smallfont)\n",
    "#     ax4.set_xlabel(label, fontsize=largefont)\n",
    "#     ax4.set_ylabel('Average Shortest Path', fontsize=largefont)\n",
    "#     ax4.legend((line1, line2), ('Incomplete Info', 'Complete Info'), fontsize=smallfont)\n",
    "#     ax4.set_ylim(bottom=0)\n",
    "\n",
    "    \n",
    "    ###\n",
    "    adc_IC, adc_IC_var = calculate_avg_var(avg_degree_centrality_IC)\n",
    "    adc_C, adc_C_var = calculate_avg_var(avg_degree_centrality_C)\n",
    "    adc_R, adc_R_var = calculate_avg_var(avg_degree_centrality_R)\n",
    "    \n",
    "    dc_color = 'teal'\n",
    "    ax5 = axs[2, i]\n",
    "    line1, = ax5.plot(increments, adc_IC, color='crimson', marker='o', linestyle=main_line, linewidth=lw, markersize=ms)\n",
    "    line2, = ax5.plot(increments, adc_C, color='mediumseagreen', linestyle=sub_line, linewidth=lw, markersize=ms)\n",
    "    line3, = ax5.plot(increments, adc_R, color='royalblue', linestyle=sub_line, linewidth=lw, markersize=ms)\n",
    "    ax5.tick_params(labelsize = smallfont)\n",
    "    ax5.set_xlabel(label, fontsize=largefont, labelpad=labelpad_x)\n",
    "    if i == 0:\n",
    "        ax5.set_ylabel('Avg Degree \\n Centrality', fontsize=largefont, labelpad=labelpad_y)\n",
    "        ax5.legend((line1, line2, line3), ('Biased', 'Complete', 'Rational'), fontsize=smallfont)\n",
    "    ax5.set_xlim(increments[0] - 0.01, increments[-1] + 0.01)\n",
    "    ax5.set_xticks(np.arange(increments[0], increments[-1] + 0.2, 0.2))\n",
    "    ax5.set_ylim(-0.01, 0.61)\n",
    "\n",
    "    #     ax5.set_ylim(top=0.7)\n",
    "\n",
    "    \n",
    "#     vdc_IC, vdc_IC_var = calculate_avg_var(var_degree_centrality_IC)\n",
    "#     vdc_C, vdc_C_var = calculate_avg_var(var_degree_centrality_C)\n",
    "    \n",
    "#     ax6 = axs[1,1]\n",
    "#     line1, = ax6.plot(increments, vdc_IC, color=dc_color, marker='o', linestyle='dashed', linewidth=lw, markersize=ms)\n",
    "#     line2, = ax6.plot(increments, vdc_C, color=dc_color, linestyle='solid', linewidth=lw, markersize=ms)\n",
    "#     ax6.tick_params(labelsize = smallfont)\n",
    "#     ax6.set_xlabel(label, fontsize=largefont)\n",
    "#     ax6.set_ylabel('Variance Degree Centrality', fontsize=largefont)\n",
    "#     ax6.set_ylim(top=0.012)\n",
    "#     ax6.set_ylim(bottom=0)\n",
    "#     ax6.legend((line1, line2), ('Incomplete Info', 'Complete Info'), fontsize=smallfont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seg_plot(i, axs, label, increments, \\\n",
    "            freeman, avg_degree_centrality, information):\n",
    "    \n",
    "    freeman_avg = []\n",
    "    for f in freeman:\n",
    "        avg, var = calculate_avg_var(f)\n",
    "        freeman_avg.append(avg)\n",
    "        \n",
    "    smallfont = 14\n",
    "    largefont = 18\n",
    "    lw = 4\n",
    "    ms = 8\n",
    "    labelpad_y = -5\n",
    "    labelpad_x = 5\n",
    "    \n",
    "    # colors = ['greenyellow','mediumseagreen','crimson','royalblue']\n",
    "    # linestyles = ['solid','solid','dashed','solid']\n",
    "    # markers = [None, None, 'o', None]\n",
    "    # labels = [r'$\\beta = 3$', r'$\\beta = 5$', r'$\\beta = 7$', r'$\\beta = 9$']\n",
    "    # labels = ['4 Groups', 'Dominant', 'Base']\n",
    "\n",
    "    colors = ['greenyellow','mediumseagreen','royalblue','crimson']\n",
    "    linestyles = ['solid','solid','solid','dashed']\n",
    "    markers = [None, None, None, 'o']\n",
    "    labels = ['4 Types', 'Dominant', 'Correlated', 'Base']\n",
    "\n",
    "    \n",
    "    ###\n",
    "    lines = []\n",
    "    ax1 = axs[0, i]\n",
    "    for case, f in enumerate(freeman_avg):\n",
    "        line, = ax1.plot(increments, f, color=colors[case], marker=markers[case], linestyle=linestyles[case], linewidth=lw, markersize=ms)\n",
    "        lines.append(line) \n",
    "#     line1, = ax1.plot(increments, freeman_avg[0], color='greenyellow', linestyle='solid', linewidth=lw, markersize=ms)\n",
    "#     line2, = ax1.plot(increments, freeman_avg[1], color='mediumseagreen', linestyle='solid', linewidth=lw, markersize=ms)\n",
    "#     line3, = ax1.plot(increments, freeman_avg[2], color='crimson', marker='o', linestyle='dashed', linewidth=lw, markersize=ms)\n",
    "#     line4, = ax1.plot(increments, freeman_avg[3], color='royalblue', linestyle='solid', linewidth=lw, markersize=ms)\n",
    "\n",
    "    ax1.tick_params(labelsize = smallfont)\n",
    "#     ax1.set_xlabel(label, fontsize=largefont)\n",
    "    if i == 0:\n",
    "        ax1.set_ylabel('Freeman\\'s SI', fontsize=largefont,labelpad=labelpad_y)\n",
    "    if i == 0:\n",
    "        ax1.legend(lines, labels , fontsize=smallfont-4, loc='lower right')\n",
    "    ax1.set_xlim(increments[0] - 0.01, increments[-1] + 0.01)\n",
    "    ax1.set_xticks(np.arange(increments[0], increments[-1] + 0.2, 0.2))\n",
    "    ax1.set_ylim(-0.2, 1.1)\n",
    "    ax1.set_yticks(np.arange(-0.2, 1.2, 0.2))\n",
    "\n",
    "    ###\n",
    "    info_avg = []\n",
    "    for info in information:\n",
    "        avg, var = calculate_avg_var(info)\n",
    "        info_avg.append(avg)\n",
    "        \n",
    "    lines = []\n",
    "    \n",
    "    ax2 = axs[1, i]\n",
    "    for case, info in enumerate(info_avg):\n",
    "        line, = ax2.plot(increments, info, color=colors[case], marker=markers[case], linestyle=linestyles[case], linewidth=lw, markersize=ms)\n",
    "        lines.append(line)\n",
    "#     line1, = ax2.plot(increments, info_avg[0], color='greenyellow', linestyle='solid', linewidth=lw, markersize=ms)\n",
    "#     line2, = ax2.plot(increments, info_avg[1], color='mediumseagreen',linestyle='solid', linewidth=lw, markersize=ms)\n",
    "#     line3, = ax2.plot(increments, info_avg[2], color='crimson', marker='o', linestyle='dashed', linewidth=lw, markersize=ms)\n",
    "#     line4, = ax2.plot(increments, info_avg[3], color='royalblue', linestyle='solid', linewidth=lw, markersize=ms)\n",
    "\n",
    "    ax2.tick_params(labelsize = smallfont)\n",
    "#     ax2.set_xlabel(label, fontsize=largefont)\n",
    "    if i == 0:\n",
    "        ax2.set_ylabel('Proportion of \\n Discovery', fontsize=largefont, labelpad=labelpad_y)\n",
    "#     ax2.legend((line1, line2, line3, line4), ('beta(1,3)', 'beta(1,5)', 'beta(1,7)', 'beta(1,9)'), fontsize=smallfont)\n",
    "    ax2.set_xlim(increments[0] - 0.01, increments[-1] + 0.01)\n",
    "    ax2.set_xticks(np.arange(increments[0], increments[-1] + 0.2, 0.2))\n",
    "    ax2.set_ylim(-0.01,0.71)\n",
    "    \n",
    "    ###\n",
    "    adc_avg = []\n",
    "    for adc in avg_degree_centrality:\n",
    "        avg, var = calculate_avg_var(adc)\n",
    "        adc_avg.append(avg)\n",
    "    \n",
    "    lines = []\n",
    "    \n",
    "    ax5 = axs[2, i]\n",
    "    for case, adc in enumerate(adc_avg):\n",
    "        line, = ax5.plot(increments, adc, color=colors[case], marker=markers[case], linestyle=linestyles[case], linewidth=lw, markersize=ms)\n",
    "        lines.append(line)\n",
    "#     line1, = ax5.plot(increments, adc_avg[0], color='greenyellow', linestyle='solid', linewidth=lw, markersize=ms)\n",
    "#     line2, = ax5.plot(increments, adc_avg[1], color='mediumseagreen', linestyle='solid', linewidth=lw, markersize=ms)\n",
    "#     line3, = ax5.plot(increments, adc_avg[2], color='crimson', marker='o', linestyle='dashed', linewidth=lw, markersize=ms)\n",
    "#     line4, = ax5.plot(increments, adc_avg[3], color='royalblue', linestyle='solid', linewidth=lw, markersize=ms)\n",
    "    ax5.tick_params(labelsize = smallfont)\n",
    "    ax5.set_xlabel(label, fontsize=largefont, labelpad=labelpad_x)\n",
    "    if i == 0:\n",
    "        ax5.set_ylabel('Avg Degree \\n Centrality', fontsize=largefont, labelpad=labelpad_y)\n",
    "#     ax5.legend((line1, line2, line3, line4), ('beta(1,3)', 'beta(1,5)', 'beta(1,7)', 'beta(1,9)'), fontsize=smallfont)\n",
    "    ax5.set_xlim(increments[0] - 0.01, increments[-1] + 0.01)\n",
    "    ax5.set_xticks(np.arange(increments[0], increments[-1] + 0.2, 0.2))\n",
    "    ax5.set_ylim(-0.01, 0.61)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_convergence_plot(axs, labels, increments, convergences):\n",
    "    \n",
    "    titles = ['(a)', '(b)', '(c)']\n",
    "    colors = ['tomato', 'royalblue', 'peru']\n",
    "    \n",
    "    smallfont = 20\n",
    "    largefont = 24\n",
    "    lw = 4\n",
    "    ms = 8\n",
    "    \n",
    "    for col in range(len(axs[0])):\n",
    "        for row in range(len(axs)):\n",
    "            \n",
    "            conv_IC, conv_IC_var = calculate_avg_var(convergences[(col * len(axs) + row) * 2])\n",
    "            conv_C, conv_C_var = calculate_avg_var(convergences[(col * len(axs) + row) * 2 + 1])\n",
    "            ax = axs[row,col]\n",
    "            line1, = ax.plot(increments[(col * len(axs) + row)], conv_IC, color=colors[col], marker='o', linestyle='dashed', linewidth=lw, markersize=ms)\n",
    "            line2, = ax.plot(increments[(col * len(axs) + row)], conv_C, color=colors[col], marker='o', linestyle='solid', linewidth=lw, markersize=ms)\n",
    "            ax.tick_params(labelsize = smallfont)\n",
    "            ax.set_xlabel(labels[col * row + row], fontsize=largefont)\n",
    "            ax.set_ylabel('Periods to Convergence', fontsize=largefont)\n",
    "            ax.legend((line1, line2), ('Incomplete Info', 'Complete Info'), fontsize=smallfont)\n",
    "            if(row==1):\n",
    "                ax.set_title(titles[col], y=-0.4, fontsize=largefont)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script below first calculates the statistics in batches and then uses make_plot functions to generate the plots and save it in the current directory\n",
    "Note that cases should be saved in different files ending in unique digits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check convergence\n",
    "case = 'cl'\n",
    "if (case == 'cl'):\n",
    "    increments = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "else:\n",
    "    increments = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0, 1.05, 1.1, 1.15, 1.2, 1.25, 1.3, 1.35, 1.4, 1.45, 1.5]\n",
    "files = 10\n",
    "belief = 0\n",
    "option = 1\n",
    "# IC, C = check_attribute(option, PATH, belief, case, files, increments)\n",
    "# print(IC)\n",
    "# print(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# producing all plots\n",
    "if (PLOTS):\n",
    "    root = PATH\n",
    "    belief = 6    \n",
    "    files = 30\n",
    "    \n",
    "    # 12 width x 9 height\n",
    "    fig, axs = plt.subplots(3, 2, figsize = (9,9))\n",
    "\n",
    "    for i,c in enumerate(['cl','ch']):\n",
    "        case = c\n",
    "        if (case == 'cl'):\n",
    "            label = 'Intra-type cost ($c_L$)'\n",
    "            increments = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "        else:\n",
    "            label = 'Inter-type cost ($c_H$)'\n",
    "            increments = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0, 1.05, 1.1, 1.15, 1.2, 1.25, 1.3, 1.35, 1.4, 1.45, 1.5]\n",
    "\n",
    "        # get arrays of size len(increments) containing the averages for each statistic\n",
    "        freeman, incr_segregation_C, incr_segregation_R, \\\n",
    "                    avg_degree_centrality_IC, avg_degree_centrality_C, avg_degree_centrality_R, \\\n",
    "                    information_IC, information_R \\\n",
    "                    = calculate_stats(root, belief, case, files, increments)\n",
    "\n",
    "        fig.subplots_adjust(wspace=0.25, hspace=0.15)\n",
    "        make_plot(i, axs, label, increments, \\\n",
    "                    freeman, incr_segregation_C, incr_segregation_R, \\\n",
    "                    avg_degree_centrality_IC, avg_degree_centrality_C, avg_degree_centrality_R, \\\n",
    "                    information_IC, information_R)\n",
    "        fig.align_ylabels(axs)\n",
    "    \n",
    "    plt.savefig(f'{NAME}.svg', format='svg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# producing all plots\n",
    "if SEGPLOTS:\n",
    "    root = SEGPATH\n",
    "    belief = 6    \n",
    "    files = 30\n",
    "    \n",
    "    # 12 width x 9 height\n",
    "    fig, axs = plt.subplots(3, 2, figsize = (9,9))\n",
    "\n",
    "    for i,c in enumerate(['cl','ch']):\n",
    "        case = c\n",
    "        if (case == 'cl'):\n",
    "            label = 'Intra-type cost ($c_L$)'\n",
    "            increments = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "        else:\n",
    "            label = 'Inter-type cost ($c_H$)'\n",
    "            increments = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0, 1.05, 1.1, 1.15, 1.2, 1.25, 1.3, 1.35, 1.4, 1.45, 1.5]\n",
    "\n",
    "        # get arrays of size len(increments) containing the averages for each statistic\n",
    "        \n",
    "        f = []\n",
    "        adc = []\n",
    "        info = []\n",
    "        \n",
    "        for r in root:\n",
    "            freeman, incr_segregation_C, incr_segregation_R, \\\n",
    "                        avg_degree_centrality_IC, avg_degree_centrality_C, avg_degree_centrality_R, \\\n",
    "                        information_IC, information_R \\\n",
    "                        = calculate_stats(r, belief, case, files, increments, base=False)\n",
    "            f.append(freeman)\n",
    "            adc.append(avg_degree_centrality_IC)\n",
    "            info.append(information_IC)\n",
    "            \n",
    "        fig.subplots_adjust(wspace=0.25, hspace=0.15)\n",
    "        make_seg_plot(i, axs, label, increments, \\\n",
    "                    f, adc, info)\n",
    "        fig.align_ylabels(axs)\n",
    "    \n",
    "    plt.savefig(f'{SEGNAME}.svg', format='svg', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GET_SEEDS:\n",
    "    root = SEEDPATH\n",
    "    belief = 6\n",
    "    files = 30\n",
    "    \n",
    "    seeds_IC = []\n",
    "    seeds_C = []\n",
    "    seeds_R = []\n",
    "\n",
    "    for i,c in enumerate(['cl','ch']):\n",
    "        case = c\n",
    "        if (case == 'cl'):\n",
    "            label = 'Intra-type cost ($c_L$)'\n",
    "            increments = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "        else:\n",
    "            label = 'Inter-type cost ($c_H$)'\n",
    "            increments = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0, 1.05, 1.1, 1.15, 1.2, 1.25, 1.3, 1.35, 1.4, 1.45, 1.5]\n",
    "\n",
    "        for cost in increments:\n",
    "            for iteration in range(0,files):\n",
    "                path_IC = root + \"/IC-%s-%s%s-belief%s.gpickle\" %(iteration, case, cost, belief)\n",
    "                G_IC = nx.read_gpickle(path_IC)\n",
    "                seeds_IC.append(G_IC.graph['seed'])\n",
    "\n",
    "                path_C = root + \"/C-%s-%s%s-belief%s.gpickle\" %(iteration, case, cost, belief)\n",
    "                G_C = nx.read_gpickle(path_C)\n",
    "                seeds_C.append(G_C.graph['seed'])\n",
    "\n",
    "                path_R = root + \"/IC-%s-%s%s-belief%s.gpickle\" %(iteration, case, cost, 0)\n",
    "                G_R = nx.read_gpickle(path_R)\n",
    "                seeds_R.append(G_R.graph['seed'])\n",
    "\n",
    "    print(np.all(seeds_IC == seeds_C))\n",
    "    print(np.all(seeds_IC == seeds_R))\n",
    "    \n",
    "    seeds = np.asarray(seeds_IC, dtype=int)\n",
    "    np.savetxt(f\"{root}/seeds.csv\", seeds, delimiter=\",\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few unit tests verifying statistics are calculated as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class Test(unittest.TestCase):\n",
    "\n",
    "    def setup_test_graph(self):\n",
    "        G = nx.Graph(population_breakdown = [[2],[3]])\n",
    "        G.add_node(1, group=0)\n",
    "        G.add_node(2, group=0)\n",
    "        G.add_node(3, group=1)\n",
    "        G.add_node(4, group=1)\n",
    "        G.add_node(5, group=1)\n",
    "        \n",
    "        G.add_edge(1,2)\n",
    "        G.add_edge(3,4)\n",
    "        G.add_edge(1,3)\n",
    "        G.add_edge(1,5)\n",
    "        \n",
    "        return G\n",
    "    \n",
    "\n",
    "    def test_connections_stratified(self): \n",
    "        G = self.setup_test_graph()\n",
    "        \n",
    "        strats = stratify_connections(G)\n",
    "        expect = np.asarray([[1,2],[2,1]])\n",
    "        \n",
    "        self.assertTrue(np.all(expect == strats))\n",
    "        \n",
    "    def test_connection_ratio(self):\n",
    "        G = self.setup_test_graph()\n",
    "        strats = stratify_connections(G)\n",
    "        \n",
    "        ratio = get_interconnect_ratio(strats)\n",
    "        \n",
    "        self.assertTrue(ratio == 2/4)\n",
    "        \n",
    "    def test_freeman(self):\n",
    "        G = self.setup_test_graph()\n",
    "        freeman = calculate_freeman_segregation(G)\n",
    "        pi = (2 * 2 * 3) / (5 * (5-1))\n",
    "        ratio = get_interconnect_ratio(stratify_connections(G))\n",
    "    \n",
    "        self.assertTrue(freeman == 1 - ratio / pi)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(TEST):\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c15ad233411db5c93ba4e0b66fab34a9aacfcc0d24f4600ca1410f5a73389239"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('net-env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
